{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12549052,"sourceType":"datasetVersion","datasetId":7923203},{"sourceId":5112,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":3900,"modelId":1902}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T12:57:58.660466Z","iopub.execute_input":"2025-07-23T12:57:58.660748Z","iopub.status.idle":"2025-07-23T12:57:58.934612Z","shell.execute_reply.started":"2025-07-23T12:57:58.660723Z","shell.execute_reply":"2025-07-23T12:57:58.934006Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/e-commerce-sales/Product-Level Total Sales and Metrics (mapped) - Product-Level Total Sales and Metrics (mapped).csv\n/kaggle/input/e-commerce-sales/Product-Level Eligibility Table (mapped) - Product-Level Eligibility Table (mapped).csv\n/kaggle/input/e-commerce-sales/Product-Level Ad Sales and Metrics (mapped) - Product-Level Ad Sales and Metrics (mapped).csv\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/config.json\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/pytorch_model-00002-of-00002.bin\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/tokenizer.json\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/tokenizer_config.json\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/pytorch_model.bin.index.json\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/pytorch_model-00001-of-00002.bin\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/special_tokens_map.json\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/.gitattributes\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/tokenizer.model\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/generation_config.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install llama-stack","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T12:57:58.935825Z","iopub.execute_input":"2025-07-23T12:57:58.936303Z","iopub.status.idle":"2025-07-23T12:58:11.337087Z","shell.execute_reply.started":"2025-07-23T12:57:58.936284Z","shell.execute_reply":"2025-07-23T12:58:11.336371Z"}},"outputs":[{"name":"stdout","text":"Collecting llama-stack\n  Downloading llama_stack-0.2.12-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from llama-stack) (3.12.13)\nRequirement already satisfied: fastapi<1.0,>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from llama-stack) (0.115.13)\nCollecting fire (from llama-stack)\n  Downloading fire-0.7.0.tar.gz (87 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-stack) (0.28.1)\nRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from llama-stack) (0.33.1)\nRequirement already satisfied: jinja2>=3.1.6 in /usr/local/lib/python3.11/dist-packages (from llama-stack) (3.1.6)\nRequirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from llama-stack) (4.24.0)\nCollecting llama-stack-client>=0.2.12 (from llama-stack)\n  Downloading llama_stack_client-0.2.12-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: openai>=1.66 in /usr/local/lib/python3.11/dist-packages (from llama-stack) (1.91.0)\nRequirement already satisfied: prompt-toolkit in /usr/local/lib/python3.11/dist-packages (from llama-stack) (3.0.51)\nCollecting python-dotenv (from llama-stack)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nCollecting python-jose (from llama-stack)\n  Downloading python_jose-3.5.0-py2.py3-none-any.whl.metadata (5.5 kB)\nRequirement already satisfied: pydantic>=2 in /usr/local/lib/python3.11/dist-packages (from llama-stack) (2.11.7)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from llama-stack) (2.32.4)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from llama-stack) (14.0.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from llama-stack) (75.2.0)\nRequirement already satisfied: starlette in /usr/local/lib/python3.11/dist-packages (from llama-stack) (0.46.2)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from llama-stack) (3.1.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from llama-stack) (0.9.0)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from llama-stack) (11.2.1)\nRequirement already satisfied: h11>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from llama-stack) (0.16.0)\nRequirement already satisfied: python-multipart>=0.0.20 in /usr/local/lib/python3.11/dist-packages (from llama-stack) (0.0.20)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1.0,>=0.115.0->llama-stack) (4.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.1.6->llama-stack) (3.0.2)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-stack-client>=0.2.12->llama-stack) (4.9.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from llama-stack-client>=0.2.12->llama-stack) (8.2.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-stack-client>=0.2.12->llama-stack) (1.9.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-stack-client>=0.2.12->llama-stack) (2.2.3)\nRequirement already satisfied: pyaml in /usr/local/lib/python3.11/dist-packages (from llama-stack-client>=0.2.12->llama-stack) (25.5.0)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from llama-stack-client>=0.2.12->llama-stack) (1.3.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from llama-stack-client>=0.2.12->llama-stack) (4.67.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-stack) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-stack) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-stack) (3.10)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66->llama-stack) (0.10.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->llama-stack) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->llama-stack) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->llama-stack) (0.4.1)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->llama-stack) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->llama-stack) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->llama-stack) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->llama-stack) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->llama-stack) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->llama-stack) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->llama-stack) (1.20.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->llama-stack) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->llama-stack) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->llama-stack) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->llama-stack) (6.0.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->llama-stack) (1.1.5)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->llama-stack) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->llama-stack) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->llama-stack) (0.25.1)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit->llama-stack) (0.2.13)\nCollecting ecdsa!=0.15 (from python-jose->llama-stack)\n  Downloading ecdsa-0.19.1-py2.py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: rsa!=4.1.1,!=4.4,<5.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from python-jose->llama-stack) (4.9.1)\nRequirement already satisfied: pyasn1>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from python-jose->llama-stack) (0.6.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->llama-stack) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->llama-stack) (2.5.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->llama-stack) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->llama-stack) (2.19.2)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->llama-stack) (2024.11.6)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from ecdsa!=0.15->python-jose->llama-stack) (1.17.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->llama-stack) (0.1.2)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-stack-client>=0.2.12->llama-stack) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-stack-client>=0.2.12->llama-stack) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-stack-client>=0.2.12->llama-stack) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-stack-client>=0.2.12->llama-stack) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->llama-stack-client>=0.2.12->llama-stack) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->llama-stack-client>=0.2.12->llama-stack) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->llama-stack-client>=0.2.12->llama-stack) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->llama-stack-client>=0.2.12->llama-stack) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->llama-stack-client>=0.2.12->llama-stack) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->llama-stack-client>=0.2.12->llama-stack) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->llama-stack-client>=0.2.12->llama-stack) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->llama-stack-client>=0.2.12->llama-stack) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas->llama-stack-client>=0.2.12->llama-stack) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas->llama-stack-client>=0.2.12->llama-stack) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas->llama-stack-client>=0.2.12->llama-stack) (2024.2.0)\nDownloading llama_stack-0.2.12-py3-none-any.whl (3.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading llama_stack_client-0.2.12-py3-none-any.whl (340 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.2/340.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nDownloading python_jose-3.5.0-py2.py3-none-any.whl (34 kB)\nDownloading ecdsa-0.19.1-py2.py3-none-any.whl (150 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: fire\n  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=35bee920bee3395aafed20f138e54de6a0844760bc833dd158ee262e80b66354\n  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\nSuccessfully built fire\nInstalling collected packages: python-dotenv, fire, ecdsa, python-jose, llama-stack-client, llama-stack\nSuccessfully installed ecdsa-0.19.1 fire-0.7.0 llama-stack-0.2.12 llama-stack-client-0.2.12 python-dotenv-1.1.1 python-jose-3.5.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install llama-index llama-cpp-python --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T12:58:11.337982Z","iopub.execute_input":"2025-07-23T12:58:11.338260Z","iopub.status.idle":"2025-07-23T13:00:56.641124Z","shell.execute_reply.started":"2025-07-23T12:58:11.338227Z","shell.execute_reply":"2025-07-23T13:00:56.640392Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.6/284.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.5/132.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install huggingface_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:00:56.642911Z","iopub.execute_input":"2025-07-23T13:00:56.643371Z","iopub.status.idle":"2025-07-23T13:00:59.551297Z","shell.execute_reply.started":"2025-07-23T13:00:56.643350Z","shell.execute_reply":"2025-07-23T13:00:59.550583Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.6.15)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install transformers accelerate langchain pandas sqlalchemy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:00:59.552343Z","iopub.execute_input":"2025-07-23T13:00:59.552683Z","iopub.status.idle":"2025-07-23T13:02:22.942608Z","shell.execute_reply.started":"2025-07-23T13:00:59.552641Z","shell.execute_reply":"2025-07-23T13:02:22.941686Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\nRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.41)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.66)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\nRequirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.2.3)\nRequirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.14.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\nCollecting packaging>=20.0 (from transformers)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\nDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 packaging-24.2\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\n\ndf_ads = pd.read_csv(\"/kaggle/input/e-commerce-sales/Product-Level Ad Sales and Metrics (mapped) - Product-Level Ad Sales and Metrics (mapped).csv\")\ndf_total = pd.read_csv(\"/kaggle/input/e-commerce-sales/Product-Level Eligibility Table (mapped) - Product-Level Eligibility Table (mapped).csv\")\ndf_eligibility = pd.read_csv(\"/kaggle/input/e-commerce-sales/Product-Level Total Sales and Metrics (mapped) - Product-Level Total Sales and Metrics (mapped).csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:02:22.943860Z","iopub.execute_input":"2025-07-23T13:02:22.944112Z","iopub.status.idle":"2025-07-23T13:02:23.013167Z","shell.execute_reply.started":"2025-07-23T13:02:22.944084Z","shell.execute_reply":"2025-07-23T13:02:23.012555Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import sqlite3\nconn = sqlite3.connect(\"ecommerce.db\")\n\ndf_ads.to_sql(\"product_ad_sales\", conn, if_exists=\"replace\", index=False)\ndf_eligibility.to_sql(\"product_eligibility\", conn, if_exists=\"replace\", index=False)\ndf_total.to_sql(\"product_total_sales\", conn, if_exists=\"replace\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:02:23.014082Z","iopub.execute_input":"2025-07-23T13:02:23.014769Z","iopub.status.idle":"2025-07-23T13:02:23.110268Z","shell.execute_reply.started":"2025-07-23T13:02:23.014748Z","shell.execute_reply":"2025-07-23T13:02:23.109741Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"4381"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"pd.read_sql_query(\"SELECT * FROM product_ad_sales LIMIT 5\", conn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:02:23.111022Z","iopub.execute_input":"2025-07-23T13:02:23.111261Z","iopub.status.idle":"2025-07-23T13:02:23.133084Z","shell.execute_reply.started":"2025-07-23T13:02:23.111245Z","shell.execute_reply":"2025-07-23T13:02:23.132510Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"         date  item_id  ad_sales  impressions  ad_spend  clicks  units_sold\n0  2025-06-01        0    332.96         1963     16.87       8           3\n1  2025-06-01        1      0.00         1764     20.39      11           0\n2  2025-06-01        2     95.99          169      0.48       0           1\n3  2025-06-01        3   1001.93         6943     75.69      31           9\n4  2025-06-01        4   1096.98        59046    401.39     285           5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>item_id</th>\n      <th>ad_sales</th>\n      <th>impressions</th>\n      <th>ad_spend</th>\n      <th>clicks</th>\n      <th>units_sold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2025-06-01</td>\n      <td>0</td>\n      <td>332.96</td>\n      <td>1963</td>\n      <td>16.87</td>\n      <td>8</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2025-06-01</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>1764</td>\n      <td>20.39</td>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2025-06-01</td>\n      <td>2</td>\n      <td>95.99</td>\n      <td>169</td>\n      <td>0.48</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2025-06-01</td>\n      <td>3</td>\n      <td>1001.93</td>\n      <td>6943</td>\n      <td>75.69</td>\n      <td>31</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2025-06-01</td>\n      <td>4</td>\n      <td>1096.98</td>\n      <td>59046</td>\n      <td>401.39</td>\n      <td>285</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"pd.read_sql_query(\"SELECT * FROM product_eligibility LIMIT 5\", conn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:02:23.133818Z","iopub.execute_input":"2025-07-23T13:02:23.134129Z","iopub.status.idle":"2025-07-23T13:02:23.142786Z","shell.execute_reply.started":"2025-07-23T13:02:23.134111Z","shell.execute_reply":"2025-07-23T13:02:23.142081Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"         date  item_id  total_sales  total_units_ordered\n0  2025-06-01        0       309.99                    1\n1  2025-06-01        3       338.00                    2\n2  2025-06-01        4       617.99                    3\n3  2025-06-01        9       219.00                    1\n4  2025-06-01       12       534.00                    3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>item_id</th>\n      <th>total_sales</th>\n      <th>total_units_ordered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2025-06-01</td>\n      <td>0</td>\n      <td>309.99</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2025-06-01</td>\n      <td>3</td>\n      <td>338.00</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2025-06-01</td>\n      <td>4</td>\n      <td>617.99</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2025-06-01</td>\n      <td>9</td>\n      <td>219.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2025-06-01</td>\n      <td>12</td>\n      <td>534.00</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"pd.read_sql_query(\"SELECT * FROM product_total_sales LIMIT 5\", conn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:02:23.146108Z","iopub.execute_input":"2025-07-23T13:02:23.146376Z","iopub.status.idle":"2025-07-23T13:02:23.166152Z","shell.execute_reply.started":"2025-07-23T13:02:23.146355Z","shell.execute_reply":"2025-07-23T13:02:23.165449Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"  eligibility_datetime_utc  item_id  eligibility  \\\n0       2025-06-04 8:50:07       29            0   \n1       2025-06-04 8:50:07      270            1   \n2       2025-06-04 8:50:07       31            1   \n3       2025-06-04 8:50:07       26            1   \n4       2025-06-04 8:50:07       25            1   \n\n                                             message  \n0  This product's cost to Amazon does not allow u...  \n1                                               None  \n2                                               None  \n3                                               None  \n4                                               None  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eligibility_datetime_utc</th>\n      <th>item_id</th>\n      <th>eligibility</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2025-06-04 8:50:07</td>\n      <td>29</td>\n      <td>0</td>\n      <td>This product's cost to Amazon does not allow u...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2025-06-04 8:50:07</td>\n      <td>270</td>\n      <td>1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2025-06-04 8:50:07</td>\n      <td>31</td>\n      <td>1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2025-06-04 8:50:07</td>\n      <td>26</td>\n      <td>1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2025-06-04 8:50:07</td>\n      <td>25</td>\n      <td>1</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer,pipeline\nimport torch\n\nmodel_path = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", torch_dtype=torch.float16)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:02:23.166962Z","iopub.execute_input":"2025-07-23T13:02:23.167201Z","iopub.status.idle":"2025-07-23T13:04:24.827878Z","shell.execute_reply.started":"2025-07-23T13:02:23.167184Z","shell.execute_reply":"2025-07-23T13:04:24.827211Z"}},"outputs":[{"name":"stderr","text":"2025-07-23 13:02:40.013123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753275760.367514      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753275760.469749      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05fe8a03ab6f46c9a155e0cd59719c88"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"!pip uninstall -y llama-index\n!pip install llama-index==0.10.40 llama-index-llms-huggingface sqlalchemy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:04:24.828718Z","iopub.execute_input":"2025-07-23T13:04:24.829364Z","iopub.status.idle":"2025-07-23T13:05:00.617621Z","shell.execute_reply.started":"2025-07-23T13:04:24.829344Z","shell.execute_reply":"2025-07-23T13:05:00.616824Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: llama-index 0.12.51\nUninstalling llama-index-0.12.51:\n  Successfully uninstalled llama-index-0.12.51\nCollecting llama-index==0.10.40\n  Downloading llama_index-0.10.40-py3-none-any.whl.metadata (11 kB)\nCollecting llama-index-llms-huggingface\n  Downloading llama_index_llms_huggingface-0.5.0-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.41)\nCollecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index==0.10.40)\n  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\nCollecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index==0.10.40)\n  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\nCollecting llama-index-core<0.11.0,>=0.10.40 (from llama-index==0.10.40)\n  Downloading llama_index_core-0.10.68.post1-py3-none-any.whl.metadata (2.5 kB)\nCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index==0.10.40)\n  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\nCollecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index==0.10.40)\n  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata (3.8 kB)\nCollecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index==0.10.40)\n  Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl.metadata (8.5 kB)\nCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index==0.10.40)\n  Downloading llama_index_llms_openai-0.1.31-py3-none-any.whl.metadata (650 bytes)\nCollecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index==0.10.40)\n  Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl.metadata (728 bytes)\nCollecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.40)\n  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\nCollecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index==0.10.40)\n  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\nCollecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index==0.10.40)\n  Downloading llama_index_readers_file-0.1.33-py3-none-any.whl.metadata (5.4 kB)\nCollecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index==0.10.40)\n  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\nINFO: pip is looking at multiple versions of llama-index-llms-huggingface to determine which version is compatible with other requirements. This could take a while.\nCollecting llama-index-llms-huggingface\n  Downloading llama_index_llms_huggingface-0.4.2-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-huggingface) (0.33.1)\n  Downloading llama_index_llms_huggingface-0.4.1-py3-none-any.whl.metadata (2.9 kB)\nCollecting huggingface-hub<0.24.0,>=0.23.0 (from llama-index-llms-huggingface)\n  Downloading huggingface_hub-0.23.5-py3-none-any.whl.metadata (12 kB)\nCollecting llama-index-llms-huggingface\n  Downloading llama_index_llms_huggingface-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n  Downloading llama_index_llms_huggingface-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n  Downloading llama_index_llms_huggingface-0.3.4-py3-none-any.whl.metadata (840 bytes)\n  Downloading llama_index_llms_huggingface-0.3.3-py3-none-any.whl.metadata (840 bytes)\n  Downloading llama_index_llms_huggingface-0.3.2-py3-none-any.whl.metadata (840 bytes)\nINFO: pip is still looking at multiple versions of llama-index-llms-huggingface to determine which version is compatible with other requirements. This could take a while.\n  Downloading llama_index_llms_huggingface-0.3.1-py3-none-any.whl.metadata (789 bytes)\n  Downloading llama_index_llms_huggingface-0.3.0-py3-none-any.whl.metadata (840 bytes)\n  Downloading llama_index_llms_huggingface-0.2.8-py3-none-any.whl.metadata (841 bytes)\nCollecting text-generation<0.8.0,>=0.7.0 (from llama-index-llms-huggingface)\n  Downloading text_generation-0.7.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-huggingface) (2.6.0+cu124)\nRequirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.52.4)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.2.3)\nRequirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.67.1)\nRequirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.40) (1.91.0)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (3.12.13)\nRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (0.6.7)\nRequirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.2.18)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.0.8)\nRequirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (0.28.1)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.6.0)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (3.5)\nRequirement already satisfied: nltk!=3.9,>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (3.9.1)\nRequirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2.2.3)\nRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (11.2.1)\nRequirement already satisfied: pydantic<3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2.11.7)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (8.5.0)\nRequirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (0.9.0)\nRequirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (0.9.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.17.2)\nCollecting llamaindex-py-client<0.2.0,>=0.1.19 (from llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl.metadata (760 bytes)\nRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.40) (4.13.4)\nCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.40)\n  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.40) (0.0.26)\nRequirement already satisfied: llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40) (0.6.43)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\nINFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\nCollecting transformers<5.0.0,>=4.37.0 (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface)\n  Downloading transformers-4.53.3-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.52.2-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.52.1-py3-none-any.whl.metadata (38 kB)\nINFO: pip is still looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n  Downloading transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\n  Downloading transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading transformers-4.50.2-py3-none-any.whl.metadata (39 kB)\n  Downloading transformers-4.50.1-py3-none-any.whl.metadata (39 kB)\n  Downloading transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\n  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.11.6)\nCollecting tokenizers<0.21,>=0.20 (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface)\n  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.5.3)\nINFO: pip is looking at multiple versions of transformers[torch] to determine which version is compatible with other requirements. This could take a while.\nINFO: pip is still looking at multiple versions of transformers[torch] to determine which version is compatible with other requirements. This could take a while.\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\nRequirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (1.8.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (7.0.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.20.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.40) (2.7)\nRequirement already satisfied: llama-cloud-services>=0.6.43 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40) (0.6.43)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (4.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (3.10)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (0.16.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.5.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2.4.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.40) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.40) (0.10.0)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.40) (1.3.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.5.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.1.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (3.26.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2025.2)\nRequirement already satisfied: llama-cloud==0.1.32 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.43->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40) (0.1.32)\nINFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\nCollecting llama-cloud-services>=0.6.43 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Using cached llama_cloud_services-0.6.51-py3-none-any.whl.metadata (3.5 kB)\nCollecting llama-cloud==0.1.34 (from llama-cloud-services>=0.6.43->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud-0.1.34-py3-none-any.whl.metadata (1.2 kB)\nCollecting llama-cloud-services>=0.6.43 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Using cached llama_cloud_services-0.6.50-py3-none-any.whl.metadata (3.5 kB)\n  Using cached llama_cloud_services-0.6.49-py3-none-any.whl.metadata (3.5 kB)\n  Using cached llama_cloud_services-0.6.48-py3-none-any.whl.metadata (3.5 kB)\n  Using cached llama_cloud_services-0.6.47-py3-none-any.whl.metadata (3.5 kB)\nCollecting llama-cloud==0.1.33 (from llama-cloud-services>=0.6.43->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud-0.1.33-py3-none-any.whl.metadata (1.2 kB)\nCollecting llama-cloud-services>=0.6.43 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Using cached llama_cloud_services-0.6.46-py3-none-any.whl.metadata (3.5 kB)\n  Using cached llama_cloud_services-0.6.45-py3-none-any.whl.metadata (3.5 kB)\nINFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n  Using cached llama_cloud_services-0.6.44-py3-none-any.whl.metadata (3.5 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Using cached llama_parse-0.6.51-py3-none-any.whl.metadata (6.9 kB)\n  Using cached llama_parse-0.6.50-py3-none-any.whl.metadata (6.9 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Using cached llama_parse-0.6.49-py3-none-any.whl.metadata (6.9 kB)\n  Using cached llama_parse-0.6.48-py3-none-any.whl.metadata (6.9 kB)\n  Using cached llama_parse-0.6.47-py3-none-any.whl.metadata (6.9 kB)\n  Using cached llama_parse-0.6.46-py3-none-any.whl.metadata (6.9 kB)\n  Using cached llama_parse-0.6.45-py3-none-any.whl.metadata (6.9 kB)\n  Using cached llama_parse-0.6.44-py3-none-any.whl.metadata (6.9 kB)\n  Using cached llama_parse-0.6.43-py3-none-any.whl.metadata (6.9 kB)\n  Downloading llama_parse-0.6.42-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.42 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.42-py3-none-any.whl.metadata (3.5 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.41-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.41 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.41-py3-none-any.whl.metadata (3.5 kB)\nCollecting llama-cloud==0.1.30 (from llama-cloud-services>=0.6.41->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud-0.1.30-py3-none-any.whl.metadata (1.2 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.40-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.40 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.40-py3-none-any.whl.metadata (3.5 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.39-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.39 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.39-py3-none-any.whl.metadata (3.5 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.38-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.37 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.38-py3-none-any.whl.metadata (3.5 kB)\nCollecting llama-cloud==0.1.29 (from llama-cloud-services>=0.6.37->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud-0.1.29-py3-none-any.whl.metadata (1.2 kB)\nCollecting llama-cloud-services>=0.6.37 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.37-py3-none-any.whl.metadata (3.5 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.37-py3-none-any.whl.metadata (6.9 kB)\n  Downloading llama_parse-0.6.36-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.36 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.36-py3-none-any.whl.metadata (3.5 kB)\nCollecting llama-cloud==0.1.28 (from llama-cloud-services>=0.6.36->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud-0.1.28-py3-none-any.whl.metadata (1.2 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.35-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.35 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.35-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-cloud==0.1.27 (from llama-cloud-services>=0.6.35->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud-0.1.27-py3-none-any.whl.metadata (1.2 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.34-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.32 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.34-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-cloud==0.1.26 (from llama-cloud-services>=0.6.32->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud-0.1.26-py3-none-any.whl.metadata (1.2 kB)\nCollecting llama-cloud-services>=0.6.32 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.33-py3-none-any.whl.metadata (3.4 kB)\n  Downloading llama_cloud_services-0.6.32-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.33-py3-none-any.whl.metadata (6.9 kB)\n  Downloading llama_parse-0.6.32-py3-none-any.whl.metadata (6.9 kB)\n  Downloading llama_parse-0.6.31-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.31 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.31-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.30-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.30 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.30-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-cloud==0.1.23 (from llama-cloud-services>=0.6.30->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud-0.1.23-py3-none-any.whl.metadata (1.1 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.28-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.28 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.29-py3-none-any.whl.metadata (3.4 kB)\n  Downloading llama_cloud_services-0.6.28-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.27-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.27 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.27-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.26-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.26 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.26-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.25-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.24 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.25-py3-none-any.whl.metadata (3.4 kB)\n  Downloading llama_cloud_services-0.6.24-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.24-py3-none-any.whl.metadata (6.9 kB)\n  Downloading llama_parse-0.6.23-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.23 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.23-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-cloud==0.1.22 (from llama-cloud-services>=0.6.23->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud-0.1.22-py3-none-any.whl.metadata (1.2 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.22-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.22 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.22-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-cloud==0.1.19 (from llama-cloud-services>=0.6.22->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.21-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.21 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.21-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.20-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.20 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.20-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.18-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.17 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.19-py3-none-any.whl.metadata (3.4 kB)\n  Downloading llama_cloud_services-0.6.18-py3-none-any.whl.metadata (3.4 kB)\n  Downloading llama_cloud_services-0.6.17-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.16-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.16 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.16-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.12-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.12 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.15-py3-none-any.whl.metadata (3.4 kB)\n  Downloading llama_cloud_services-0.6.14-py3-none-any.whl.metadata (3.4 kB)\n  Downloading llama_cloud_services-0.6.12-py3-none-any.whl.metadata (3.4 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.9-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.9 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.11-py3-none-any.whl.metadata (3.5 kB)\n  Downloading llama_cloud_services-0.6.10-py3-none-any.whl.metadata (3.5 kB)\n  Downloading llama_cloud_services-0.6.9-py3-none-any.whl.metadata (2.9 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.4.post1-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.4 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.8-py3-none-any.whl.metadata (2.9 kB)\n  Downloading llama_cloud_services-0.6.7-py3-none-any.whl.metadata (2.9 kB)\n  Downloading llama_cloud_services-0.6.6-py3-none-any.whl.metadata (2.9 kB)\n  Downloading llama_cloud_services-0.6.5-py3-none-any.whl.metadata (2.9 kB)\n  Downloading llama_cloud_services-0.6.4-py3-none-any.whl.metadata (2.9 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.4-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.3 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.3-py3-none-any.whl.metadata (2.9 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.2-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.2 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.2-py3-none-any.whl.metadata (2.8 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.1-py3-none-any.whl.metadata (6.9 kB)\nCollecting llama-cloud-services>=0.6.1 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.1-py3-none-any.whl.metadata (2.7 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.6.0-py3-none-any.whl.metadata (6.8 kB)\nCollecting llama-cloud-services (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_cloud_services-0.6.0-py3-none-any.whl.metadata (2.7 kB)\nCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.40)\n  Downloading llama_parse-0.5.20-py3-none-any.whl.metadata (6.9 kB)\nINFO: pip is looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n  Downloading llama_parse-0.5.19-py3-none-any.whl.metadata (7.0 kB)\n  Downloading llama_parse-0.5.18-py3-none-any.whl.metadata (7.0 kB)\n  Downloading llama_parse-0.5.17-py3-none-any.whl.metadata (7.0 kB)\n  Downloading llama_parse-0.5.16-py3-none-any.whl.metadata (7.0 kB)\n  Downloading llama_parse-0.5.15-py3-none-any.whl.metadata (7.0 kB)\n  Downloading llama_parse-0.5.14-py3-none-any.whl.metadata (6.9 kB)\n  Downloading llama_parse-0.5.13-py3-none-any.whl.metadata (6.9 kB)\nINFO: pip is still looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n  Downloading llama_parse-0.5.12-py3-none-any.whl.metadata (6.9 kB)\n  Downloading llama_parse-0.5.11-py3-none-any.whl.metadata (6.9 kB)\n  Downloading llama_parse-0.5.10-py3-none-any.whl.metadata (6.9 kB)\n  Downloading llama_parse-0.5.9-py3-none-any.whl.metadata (6.9 kB)\n  Downloading llama_parse-0.5.8-py3-none-any.whl.metadata (6.4 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading llama_parse-0.5.7-py3-none-any.whl.metadata (6.4 kB)\n  Downloading llama_parse-0.5.6-py3-none-any.whl.metadata (6.1 kB)\n  Downloading llama_parse-0.5.5-py3-none-any.whl.metadata (6.1 kB)\n  Downloading llama_parse-0.5.4-py3-none-any.whl.metadata (6.1 kB)\n  Downloading llama_parse-0.5.3-py3-none-any.whl.metadata (4.5 kB)\n  Downloading llama_parse-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n  Downloading llama_parse-0.5.1-py3-none-any.whl.metadata (4.5 kB)\n  Downloading llama_parse-0.5.0-py3-none-any.whl.metadata (4.4 kB)\n  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0.0->llama-index-core<0.11.0,>=0.10.40->llama-index==0.10.40) (2024.2.0)\nDownloading llama_index-0.10.40-py3-none-any.whl (6.8 kB)\nDownloading llama_index_llms_huggingface-0.2.8-py3-none-any.whl (11 kB)\nDownloading huggingface_hub-0.23.5-py3-none-any.whl (402 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.8/402.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\nDownloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\nDownloading llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\nDownloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\nDownloading llama_index_legacy-0.9.48.post4-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index_llms_openai-0.1.31-py3-none-any.whl (12 kB)\nDownloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\nDownloading llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\nDownloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\nDownloading llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\nDownloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\nDownloading text_generation-0.7.0-py3-none-any.whl (12 kB)\nDownloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\nDownloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdf, huggingface-hub, tokenizers, text-generation, llamaindex-py-client, llama-index-core, llama-index-llms-openai, llama-index-agent-openai, transformers, llama-parse, llama-index-program-openai, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-readers-file, llama-index-question-gen-openai, llama-index-multi-modal-llms-openai, llama-index-legacy, llama-index-indices-managed-llama-cloud, llama-index-cli, llama-index-llms-huggingface, llama-index\n  Attempting uninstall: pypdf\n    Found existing installation: pypdf 5.7.0\n    Uninstalling pypdf-5.7.0:\n      Successfully uninstalled pypdf-5.7.0\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.33.1\n    Uninstalling huggingface-hub-0.33.1:\n      Successfully uninstalled huggingface-hub-0.33.1\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: llama-index-core\n    Found existing installation: llama-index-core 0.12.52\n    Uninstalling llama-index-core-0.12.52:\n      Successfully uninstalled llama-index-core-0.12.52\n  Attempting uninstall: llama-index-llms-openai\n    Found existing installation: llama-index-llms-openai 0.4.7\n    Uninstalling llama-index-llms-openai-0.4.7:\n      Successfully uninstalled llama-index-llms-openai-0.4.7\n  Attempting uninstall: llama-index-agent-openai\n    Found existing installation: llama-index-agent-openai 0.4.12\n    Uninstalling llama-index-agent-openai-0.4.12:\n      Successfully uninstalled llama-index-agent-openai-0.4.12\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.52.4\n    Uninstalling transformers-4.52.4:\n      Successfully uninstalled transformers-4.52.4\n  Attempting uninstall: llama-parse\n    Found existing installation: llama-parse 0.6.43\n    Uninstalling llama-parse-0.6.43:\n      Successfully uninstalled llama-parse-0.6.43\n  Attempting uninstall: llama-index-program-openai\n    Found existing installation: llama-index-program-openai 0.3.2\n    Uninstalling llama-index-program-openai-0.3.2:\n      Successfully uninstalled llama-index-program-openai-0.3.2\n  Attempting uninstall: llama-index-embeddings-openai\n    Found existing installation: llama-index-embeddings-openai 0.3.1\n    Uninstalling llama-index-embeddings-openai-0.3.1:\n      Successfully uninstalled llama-index-embeddings-openai-0.3.1\n  Attempting uninstall: llama-index-readers-llama-parse\n    Found existing installation: llama-index-readers-llama-parse 0.4.0\n    Uninstalling llama-index-readers-llama-parse-0.4.0:\n      Successfully uninstalled llama-index-readers-llama-parse-0.4.0\n  Attempting uninstall: llama-index-readers-file\n    Found existing installation: llama-index-readers-file 0.4.11\n    Uninstalling llama-index-readers-file-0.4.11:\n      Successfully uninstalled llama-index-readers-file-0.4.11\n  Attempting uninstall: llama-index-question-gen-openai\n    Found existing installation: llama-index-question-gen-openai 0.3.1\n    Uninstalling llama-index-question-gen-openai-0.3.1:\n      Successfully uninstalled llama-index-question-gen-openai-0.3.1\n  Attempting uninstall: llama-index-multi-modal-llms-openai\n    Found existing installation: llama-index-multi-modal-llms-openai 0.5.3\n    Uninstalling llama-index-multi-modal-llms-openai-0.5.3:\n      Successfully uninstalled llama-index-multi-modal-llms-openai-0.5.3\n  Attempting uninstall: llama-index-indices-managed-llama-cloud\n    Found existing installation: llama-index-indices-managed-llama-cloud 0.7.10\n    Uninstalling llama-index-indices-managed-llama-cloud-0.7.10:\n      Successfully uninstalled llama-index-indices-managed-llama-cloud-0.7.10\n  Attempting uninstall: llama-index-cli\n    Found existing installation: llama-index-cli 0.4.4\n    Uninstalling llama-index-cli-0.4.4:\n      Successfully uninstalled llama-index-cli-0.4.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nllama-cloud-services 0.6.43 requires llama-index-core>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\ndatasets 3.6.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.23.5 which is incompatible.\ndiffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.23.5 which is incompatible.\ngradio 5.31.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.23.5 which is incompatible.\npeft 0.15.2 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.23.5 llama-index-0.10.40 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.68.post1 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48.post4 llama-index-llms-huggingface-0.2.8 llama-index-llms-openai-0.1.31 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.33 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 llamaindex-py-client-0.1.19 pypdf-4.3.1 text-generation-0.7.0 tokenizers-0.20.3 transformers-4.46.3\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from sqlalchemy import create_engine\nfrom llama_index.core import SQLDatabase\nfrom llama_index.core.query_engine import NLSQLTableQueryEngine\nfrom llama_index.llms.huggingface import HuggingFaceLLM\nllm = HuggingFaceLLM(model=model, tokenizer=tokenizer)\nengine = create_engine(\"sqlite:////kaggle/working/ecommerce.db\")\nsql_db = SQLDatabase(engine)\nquery_engine = NLSQLTableQueryEngine(sql_database=sql_db, llm=llm, embed_model=\"embed_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:05:00.618759Z","iopub.execute_input":"2025-07-23T13:05:00.619067Z","iopub.status.idle":"2025-07-23T13:05:04.151828Z","shell.execute_reply.started":"2025-07-23T13:05:00.619030Z","shell.execute_reply":"2025-07-23T13:05:04.151208Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import sqlite3\nconn = sqlite3.connect(\"ecommerce.db\")  \nprint(\"Tables:\", conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall())\nfor table in ['product_ad_sales', 'product_eligibility', 'product_total_sales']:\n    print(f\"\\nStructure of table: {table}\")\n    print(conn.execute(f\"PRAGMA table_info({table});\").fetchall())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:05:04.152823Z","iopub.execute_input":"2025-07-23T13:05:04.153490Z","iopub.status.idle":"2025-07-23T13:05:04.159172Z","shell.execute_reply.started":"2025-07-23T13:05:04.153461Z","shell.execute_reply":"2025-07-23T13:05:04.158270Z"}},"outputs":[{"name":"stdout","text":"Tables: [('product_ad_sales',), ('product_eligibility',), ('product_total_sales',)]\n\nStructure of table: product_ad_sales\n[(0, 'date', 'TEXT', 0, None, 0), (1, 'item_id', 'INTEGER', 0, None, 0), (2, 'ad_sales', 'REAL', 0, None, 0), (3, 'impressions', 'INTEGER', 0, None, 0), (4, 'ad_spend', 'REAL', 0, None, 0), (5, 'clicks', 'INTEGER', 0, None, 0), (6, 'units_sold', 'INTEGER', 0, None, 0)]\n\nStructure of table: product_eligibility\n[(0, 'date', 'TEXT', 0, None, 0), (1, 'item_id', 'INTEGER', 0, None, 0), (2, 'total_sales', 'REAL', 0, None, 0), (3, 'total_units_ordered', 'INTEGER', 0, None, 0)]\n\nStructure of table: product_total_sales\n[(0, 'eligibility_datetime_utc', 'TEXT', 0, None, 0), (1, 'item_id', 'INTEGER', 0, None, 0), (2, 'eligibility', 'INTEGER', 0, None, 0), (3, 'message', 'TEXT', 0, None, 0)]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def ask_agent(nl_question):\n    prompt = f\"\"\"You are an AI assistant.\nUse the following SQLite tables to answer the question:\n\nTables:\n1. product_ad_sales(date, item_id, ad_sales, impressions, ad_spend, clicks, units_sold)\n2. product_eligibility(date, item_id, total_sales, total_units_ordered)\n3. product_total_sales(eligibility_datetime_utc, item_id, eligibility, message)\n\nConvert the question into a valid SQLite SQL query and answer it by querying these tables.\n\nQuestion: \"{nl_question}\"\n\"\"\"\n    return query_engine.query(prompt)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:05:04.159953Z","iopub.execute_input":"2025-07-23T13:05:04.160244Z","iopub.status.idle":"2025-07-23T13:05:04.182251Z","shell.execute_reply.started":"2025-07-23T13:05:04.160219Z","shell.execute_reply":"2025-07-23T13:05:04.181475Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(ask_agent(\"What is my total sales?\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:05:04.183028Z","iopub.execute_input":"2025-07-23T13:05:04.183203Z","iopub.status.idle":"2025-07-23T13:05:12.112226Z","shell.execute_reply.started":"2025-07-23T13:05:04.183189Z","shell.execute_reply":"2025-07-23T13:05:12.111593Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n\nThe total sales for item 1 is 199.99.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(ask_agent(\"Calculate the RoAS (Return on Ad Spend).\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:05:12.113042Z","iopub.execute_input":"2025-07-23T13:05:12.113299Z","iopub.status.idle":"2025-07-23T13:05:46.466819Z","shell.execute_reply.started":"2025-07-23T13:05:12.113282Z","shell.execute_reply":"2025-07-23T13:05:46.465977Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n\nTo calculate the RoAS (Return on Ad Spend), you need to join the product_ad_sales table with the product_total_sales table on the item_id column. Then, you can use the following SQL query:\n\nSELECT product_ad_sales.item_id, \n       product_ad_sales.ad_spend, \n       product_ad_sales.units_sold, \n       product_ad_sales.impressions, \n       product_ad_sales.clicks, \n       product_ad_sales.ad_sales, \n       (product_ad_sales.ad_sales / product_ad_sales.ad_spend) AS RoAS\nFROM product_ad_sales\nINNER JOIN product_total_sales\nON product_ad_sales.item_id = product_total_sales.item_id\nWHERE product_total_sales.eligibility = 'eligible'\n\nThis query will give you the RoAS for all eligible products. If you want to calculate the RoAS for a specific product\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"print(ask_agent(\"Which product had the highest CPC (Cost Per Click)?\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:05:46.467644Z","iopub.execute_input":"2025-07-23T13:05:46.467966Z","iopub.status.idle":"2025-07-23T13:06:00.300040Z","shell.execute_reply.started":"2025-07-23T13:05:46.467940Z","shell.execute_reply":"2025-07-23T13:06:00.299228Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n\nThe product with the highest CPC is product 22, with a CPC of 10.21.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import shutil\n\nshutil.copytree(\n    \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\",\n    \"/kaggle/working/mistral_model\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:06:00.300930Z","iopub.execute_input":"2025-07-23T13:06:00.301197Z","iopub.status.idle":"2025-07-23T13:08:23.778792Z","shell.execute_reply.started":"2025-07-23T13:06:00.301179Z","shell.execute_reply":"2025-07-23T13:08:23.778032Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/mistral_model'"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}